{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM5itWPDTmUXBAhgYGQKUEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TruongHieuDEV/MachineLearning/blob/main/Kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBLDPLUNXORh"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cdist\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('anh.jpg')\n",
        "new_width = 360\n",
        "new_height = 480\n",
        "resized_img = np.array(img.resize((new_width, new_height)))\n",
        "pixel = []\n",
        "for i in range(new_height):\n",
        "  for j in range(new_width):\n",
        "    pixel.append(resized_img[i, j])\n",
        "pixel = np.array(pixel).astype(np.uint8)"
      ],
      "metadata": {
        "id": "EGh53hujvw6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class KMean():\n",
        "  def __init__(self, k, max_iterations):\n",
        "    self.k = k\n",
        "    self.max_iterations = max_iterations\n",
        "    self.all_centroids = []\n",
        "    self.all_labels = []\n",
        "  def fit(self, dataSet):\n",
        "    numFeatures = dataSet.shape[1]\n",
        "    centroids = self.get_random_centroids(dataSet, numFeatures)\n",
        "    self.all_centroids.append(centroids)\n",
        "    self.all_labels.append(None)\n",
        "    \n",
        "    iterations = 0\n",
        "    oldCentroids = None\n",
        "    while not self.should_stop(oldCentroids, centroids, iterations):\n",
        "      oldCentroids = centroids\n",
        "      iterations += 1\n",
        "\n",
        "      labels = self.get_labels(dataSet, centroids)\n",
        "      self.all_labels.append(labels)\n",
        "\n",
        "      centroids = self.get_centroids(dataSet, labels)\n",
        "      self.all_centroids.append(centroids)\n",
        "    return centroids\n",
        "  def get_random_centroids(self, dataSet, numFeatures):\n",
        "    return dataSet[np.random.choice(dataSet.shape[0], k, replace=False)]\n",
        "  def get_labels(self, dataSet, centroids):\n",
        "    return np.argmin(cdist(dataSet, centroids), axis = 1)\n",
        "  def should_stop(self, oldCentroids, centroids, iterations):\n",
        "    if iterations > self.max_iterations:\n",
        "      return True\n",
        "    return np.all(oldCentroids==centroids)\n",
        "  def get_centroids(self, dataSet, labels):\n",
        "    centroids = []\n",
        "    for i in range(self.k):\n",
        "      data_i = dataSet[labels==i]\n",
        "      centroids.append(np.mean(data_i, axis=0))\n",
        "    return np.array(centroids)"
      ],
      "metadata": {
        "id": "Ks0MKaWuYbgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "kmean = KMean(k, max_iterations=10)\n",
        "centroids = kmean.fit(pixel)\n",
        "pixel_new = pixel.copy()\n",
        "print(centroids)\n",
        "labels = kmean.all_labels[-1]\n",
        "for j in range(k):\n",
        "  pixel_new[labels==j] = centroids[j]\n",
        "pos = 0\n",
        "img_new = np.zeros((new_height, new_width, 3))\n",
        "for x in range(new_height):\n",
        "  for y in range(new_width):\n",
        "    img_new[x][y] = pixel_new[pos]\n",
        "    pos += 1\n",
        "img_new = img_new.astype(np.uint8)\n",
        "img = Image.fromarray(img_new, mode='RGB')\n",
        "img.show()"
      ],
      "metadata": {
        "id": "Zv9CubXzcpU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "color = ['green', 'blue', 'orange']\n",
        "gs = GridSpec(nrows=int(np.sqrt(len(kmean.all_centroids)) + 5), ncols=int(np.sqrt(len(kmean.all_centroids)) ))\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
        "plt.figure(figsize=(100,100))\n",
        "for i in range(len(kmean.all_centroids)):\n",
        "  ax = plt.subplot(gs[i])\n",
        "  if i == 0:\n",
        "    plt.scatter(pixel[:, 0], pixel[:, 1], s=50, color='red', alpha=0.5)\n",
        "    centroids_i = kmean.all_centroids[i]\n",
        "    for j in range(kmean.k):\n",
        "      plt.scatter(centroids_i[j, 0], centroids_i[j, 1], s=1000, marker='x', color='red')\n",
        "    plt.title('All points in original dataset')\n",
        "  else:\n",
        "    centroids_i = kmean.all_centroids[i]\n",
        "    labels = kmean.all_labels[i]\n",
        "    for j in range(kmean.k):\n",
        "      data_i = pixel[labels==j]\n",
        "      plt.scatter(data_i[:, 0], data_i[:, 1], s=50, color=color[j], alpha=0.5)\n",
        "      plt.scatter(centroids_i[j, 0], centroids_i[j, 1], color=color[j], s=100, marker='x')\n",
        "    plt.title(r'Iteration {}'.format(i))"
      ],
      "metadata": {
        "id": "Me4e6frAdMDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmean = KMeans(n_clusters=2, max_iter=10, random_state=0)\n",
        "kmean.fit(dataset)"
      ],
      "metadata": {
        "id": "tgV0XHsYjmjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 10\n",
        "losses = []\n",
        "for k in range(1, K):\n",
        "  kmean_k = KMeans(n_clusters=k, max_iter=10, random_state=0)\n",
        "  kmean_k.fit(dataset)\n",
        "  centroids_k = kmean_k.cluster_centers_\n",
        "  dist = cdist(dataset, centroids_k)\n",
        "  loss = np.min(dist, axis=1)\n",
        "  losses.append(np.sum(loss))"
      ],
      "metadata": {
        "id": "ZCpi408YmxxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(range(1, K), losses, 'rx-', alpha=1)"
      ],
      "metadata": {
        "id": "FPhIYLD8n0o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chúng ta sẽ sử dụng elbow để tìm ra điểm mà ở độ tốc độ suy giảm của hàm biến dạng sẽ thay đổi nhiều nhất, tức là sau điểm này thì khi cluster tăng lên, hàm biến dạng cũng giảm không đáng kể. Một vấn đề nữa khi chúng ta chọn số cluster quá ít thì một số điểm dữ liễu sẽ bị phân vào cluster mà nó không thuộc về dẫn tới hiện tượng underfiting, còn ngược lại khi số lượng cluster quá nhiều thì kích thước của cluster sẽ nhỏ, dẫn tới overfiting. Do đó Elbow sẽ giúp chúng ta chọn ra một số lượng cluster tối ưu giữa overfiting và underfiting."
      ],
      "metadata": {
        "id": "-4w3b35tqsID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một số hạn chế của Kmean:\n",
        "  \n",
        "\n",
        "*   Phải chọn cụm phù hợp do dữ liệu chưa được dán nhãn nên không có thông tin về cụm bằng pp Elbow\n",
        "*   Nhảy cảm với outliers \n",
        "*   Tùy vào cách chọn centroids ban đầu mà thuật toán sẽ phân cụm theo các cách khác nhau\n",
        "*   Không hội  tụ về quy luật phân chia tổng quát với những bộ dữ liệu phức tạp\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eMX9M0ytoYy6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_I9ECjxqr0hG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}